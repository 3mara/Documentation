% Chapter 6

\chapter{Proposed Recommender System} % Main chapter title

\label{recommender} % For referencing the chapter elsewhere, use \ref{recommender} 

\lhead{Chapter 6. \emph{Proposed Recommender System}} % This is for the header on each page - perhaps a shortened title

%----------------------------------------------------------------------------------------

\section{Introduction}
Recommender systems became an important research area since the appearance of the first papers on collaborative filtering since the mid-1990s  \citep{recom_45} \citep{recom_86} \citep{recom_97}. There has been much work done both in the industry and academia on developing new approaches to recommender systems over the last decade. The interest in this area still remains high because it constitutes a problem-rich research area and because of the abundance of practical applications that help users to deal with information overload and provide personalized recommendations, content and services to them. Examples of such applications include recommending books, CDs and other products at Amazon.com \citep{recom_61}, movies by MovieLens \citep{recom_67}, and news at VERSIFI Technologies (formerly AdaptiveInfo.com) \citep{recom_14}. Moreover, some of the vendors have incorporated recommendation capabilities into their commerce servers \citep{recom_78}. However in this chapter we focus on recommending news articels to users.

The rest of this chapter is organized as follows section ~\ref{problem} defines the recommendation problem formally,  while section ~\ref{content} discusses the content based recommendation and its disadvantages, tne collaborative recommendation system is presented in section ~\ref{sec:coll}, section ~\ref{coll_content} discusses the content via collaorative technique, section ~\ref{feedback} discusses how to measure user feedback, finally section ~\ref{adv_lsa} discusses the advantages of using LSA as a similarity metric.


\section{Recommendation Problem}\label{problem}
The recommendation is used in this work to formalize the problem of estimating ratings for the articles that have not been seen by a user. Intuitively, this estimation is usually based on the ratings given by this user to other articles and on some other information that will be formally described below. Once we can estimate ratings for the yet unrated articles, we can recommend to the user the articles with the highest estimated rating(s).

More formally, int this work the recommendation problem can be formulated as follows. Let C be the set of all users in the system and let A be the set of all possible articles that can be recommended. The space A of possible articles can be very large, ranging in hundreds of thousands or even millions of items if the application is extended.
Similarly, the user space can also be very large millions in some cases. Let $u$ be a utility function that measures usefulness of article $a$ to user $c$, i.e., $u :C \times S \rightarrow R$ , where $R$ is a totally ordered set (e.g., non-negative integers or real numbers within a certain range). Then for each user $c\in C$ , we want to choose such article $a \in A$ that maximizes the user's utility. More formally
\begin{equation} \label{eq:1}
\forall c \in C,\, A_c = arg_{max u} (c,a)_{a \in A}
\end{equation}

The utility of an article is usually represented by a rating, which indicates how a particular user liked a particular item, e.g., Ahmed gave the article "\RL{انتخابات الرئاسه}" the rating of 7 (out of 10). The utility u can either be specified by the user, as is often done for the user-defined ratings, or is computed by the application, as will be shown later.


 As utility $u$ is usually not defined on the whole $C \times S$ space, but only on some subset of it. This means $u$ needs to be extrapolated to the whole space $C \times S$. In this system given users initially rate some subset of articles that they have already seen. An example of a user-article rating matrix is presented in Table ~\ref{table:1}, where ratings are specified on the scale of 1 to 5. The $\phi$ symbol for some of the ratings means that the users have not rated the corresponding article. Therefore, the recommendation engine should be able to estimate (predict) the ratings of the non-rated article/user combinations and issue appropriate recommendations based on these predictions.

\begin{table}[ht]
\caption{A fragment of a rating matrix for a movie recommender system} % title of Table
\centering  % used for centering table
\begin{tabular}{c c c c c} % centered columns (5 columns)
\hline\hline                        %inserts double horizontal lines
 & \RL{انتخابات الرئاسه} & \RL{مبارة الاهلى} & \RL{البورصه تحقق ارباح} & \RL{نتيجة الثانويه العامه} \\ [0.5ex] % inserts table 
%heading
\hline                  % inserts single horizontal line
Ahmed & 4 & 3& 2 &4  \\ % inserting body of the table
Mohamed & $\phi$ & 4 & 5 &5  \\
Aly & 2 & 2  & 4 &$\phi$  \\
Yahya & 3 & $\phi$& 5 &2 \\[1ex]      % [1ex] adds vertical space
\hline %inserts single line
\end{tabular}
\label{table:1} % is used to refer this table in the text
\end{table}

Once the unknown ratings are estimated, actual recommendations of an item to a user are made by selecting the highest rating among all the estimated ratings for that user, according to formula ~\ref{eq:1}. Alternatively, we can recommend $N$ best items to a user or a set of users to an item.
The new ratings of the not-yet-rated items can be estimated in many different ways using the methods from machine learning, approximation theory and various heuristics. Recommender systems are usually classified according to their approach to rating estimation.

Recommender systems are usually classified into the following categories, based on how recommendations are made:
\begin{itemize}
	\item Content-based recommendations: the user is recommended items similar to the ones the user preferred in the past
	\item Collaborative recommendations: the user is recommended items that people with similar tastes and preferences liked in the past
	\item Hybrid approaches: these methods combine collaborative and content-based methods
\end{itemize}


\section{Content-Based Methods}\label{content}
The content-based approach to recommendation has its roots in information retrieval \citep{recom_7} \citep{recom_89} and information filtering \citep{recom_10} research.

By using content-based recommendation methods for recommending news articles, the system tries to use the rating of the user for previously read articles (the rate could be implicit or explicit as will be shown later) and the semantic relatedness between rated items and non-read ones to predect her rate for the unread documents and recommend the top $N$ document, more formally the utility $u(c, a)$ of article $a$ for user $c$ is estimated based on the utilities $u(c ,a_i)$  assigned by user $c$ to articles $a_i \in S$ that are \textit{similar} to item $a_i$ (depending on semantic documents representation as showed in chapter ~\ref{sim}). This means the system tries to understand the commonalities among the articles user $c$ has rated high in the past. Then, only the articles that have a high degree of similarity to whatever users preferences are would get recommended.

As stated earlier, content-based systems recommend articles similar to those that a user liked in the past  \citep{recom_56}  \citep{recom_69}  \citep{recom_77}. In particular, various candidate articles are compared with articles previously rated by the user (by one of different semantic similarity metrics showed in chapter ~\ref{sim}), and the best-matching articles(s) are recommended.let ($w_{i_1},...,w_{i_k}$) be the semantic representation of document $i$, where each weight $w_{i_k}$ dentoes the importance of the concept $k$ in document $a_i$, the ContentBasedProfile(c) of user c which contains tastes and preferences of this user can be obtained from  the concepts of the documents seen and rated by the user. ContentBasedProfile(c) can be defined as a vector of weights ($w_{c_1},...,w_{c_k}$), where each weight $w_{c_i}$ denotes the importance of concept $i$ to user $c$ and can be computed from individually rated documents representation using Rocchio algorithm  \citep{recom_85}, which computes ContentBasedProfile(c) as an \textit{average} vector from an individual content vectors  \citep{recom_8}  \citep{recom_56}.
In content-based systems, the utility function $u(c, s)$ is usually defined as:
\begin{equation}\label{eq:5}
u(c,a)= score(ContentBasedProfile(c),Content(a))
\end{equation}


Moreover, utility function $u(c, s)$ is represented in terms of vectors $\vec{W}_{c_i}$   and $\vec{W}_{a_i}$ (importance of the concept $i$ to the user $c$ and in the article $a$ respectively), such as cosine similarity measure \citep{recom_7} \citep{recom_89}:
\begin{equation}\label{eq:6}
	u(c,s) = cos(\vec{W}_c, \vec{W}_S) = \frac{\vec{W}_c \cdot \vec{W}_S}{ \|\vec{W}_c\|_2 \times \|\vec{W}_S\|_2} = 
	\frac{\sum\limits_{i=1}^k w_{i,c} \cdot w_{i,s}}{\sqrt{\sum\limits_{i=1}^k w_{i,c}^2} \sqrt{\sum\limits_{i=1}^k w_{i,s}^2}}
\end{equation}


where $K$ is the total number of concepts in the system.
For example, if user $c$ reads online articles entitled (\RL{انتخابات الرئاسه},\RL{مجلس الشعب}, \RL{المجلس العسكرى},\RL{الوضع السورى},\RL{اللجنه التأسيسية}) so it can be said that this user is interested in politics, and her profile will contains high weights to the concepts related to politics realtive to other topics, hence content-based recommendation techniques will be able to recommend other politics articles to user $c$. This is the case, because these articles will have more politics-related concepts than articles on other topics (sports, technology ....), also ContentBasedProfile(c) which is defined by vector $\vec{W}_c$, will represent such concepts $k_i$ with high weights $w_{ic}$. Consequently, a recommender system using the cosine or a related similarity measure will assign higher utility $u(c, s)$ to those articles $s$ that have high-weighted politics concepts in $\vec{w}_s $ and lower utility to the ones where politics terms are weighted less.

\subsection{Limitation}
\subsubsection{Limited Content Analysis}
Content-based techniques are limited by the concepts that are explicitly associated with the articles that these systems recommend. Therefore, in order to have a sufficient set of concepts, the system has to use large set of articles.

\subsubsection{Over-Specialization}
When the system can only recommend articles that score highly against a users profile, the user is limited to being recommended articles similar to those already rated. For example, a person with no experience with sports would never receive a recommendation for even the greatest sportive events in the worlds. In addition, the problem with over-specialization is not only that the content-based systems cannot recommend items that are different from anything the user has seen before. In certain cases, items should not be recommended if they are too similar to something the user has already seen, for example if two articles entitled \RL{فوز محمد مرسى برئاسة} and \RL{محمد مرسى رئيساً لمصر } if the user reads one of them most probably she will not be satisfied with the other. Therefore, some content based recommender systems, such as DailyLearner \citep{recom_13}, filter out items not only if they are too different from users preferences, but also if they are too similar to something the user has seen before.

\subsubsection{New User Problem}
The user has to rate a sufficient number of articles before a content-based recommender system can really understand users preferences and present the user with reliable recommendations. Therefore, a new user, having very few ratings, would not be able to get accurate recommendations, this problem is addressed later.

\section{Collaborative Methods}\label{sec:coll}
In the collaborative-based recommendation(or collaborative filtering systems), the articles previously rated by other users are used to predict the utility of article for a particular user. More formally, the utility $u(c, a)$ of item $a$ for user $c$ is estimated based on the utilities $u(c_j, a)$ assigned to item $a$ by those users $c_j \in C$ who are "similar" to user c. So we have to find other "peers" of user c, i.e., other users that have similar tastesFor (rate the same articles similarly). Then, only the articles that are most liked by the peers of user $c$ would get recommended. 
That is, the value of the unknown rating $r_c$, for user c and article $a$ is usually computed as an aggregate of the ratings of some other (usually the N most similar) users for the same item $a$:

\begin{equation}\label{eq:9}
r_{c,s}=aggr_{c'\in \hat{C}} r_{c',s} 
\end{equation}
where $\hat{C}$ denotes the set of N users that are the most similar to user c and who have rated article $a$ (N can range anywhere from 1 to the number of all users). The aggregation is performed using equation ~\ref{eq:10.b}


\begin{equation}\label{eq:10.b}
r_{c,s}= k\sum_{ c'\in \hat{C}} sim(c,c')\times r_{c',s}
\end{equation}


where multiplier k serves as a normalizing factor and is usually selected as shown in formula ~\ref{eq:k}
\begin{equation}\label{eq:k}
k = \frac{1}{\sum_{c' \in \hat{C}} |sim(c,c')|}
\end{equation}

The similarity measure between the users $c$ and $c'$, $sim(c, c')$, is essentially a distance measure and is used as a weight, i.e., the more similar users $c$ and $c'$ are, the more weight rating $r_{c'}$, a will carry in the prediction of $r{c,s}$. Note that sim(x,y) is introduced in order to be able to differentiate between levels of user similarity (i.e., to be able to find a set of “closest peers” or “nearest neighbors” for each user) and at the same time simplify the rating estimation procedure. As shown in ~\ref{10b}.




\subsection{Computing similarity between users}
To compute the similarity $sim(c,c')$ between users in the collaborative recommender systems which is based on their ratings of items that both users have rated, one of two most popular approaches are used correlation and cosine-based. 

Let $A_{xy}$ be the set of all items co-rated by both users $x$ and $y$, i.e. $a_{xy}=\{a\in A|r_{x,a}\neq \phi\, \&\, r_{y,a} \neq \phi \}$. $A_xy$ is obtained by computing the intersection of sets $A_x$ and $A_y$.
The followoing sub-sections discuss the correlation based similarity and cosine based similarity
Listedb bellow the equations used to the similarity between users
\begin{itemize}
\item \textbf{Correlation based similarity}
In the correlation-based approach, the Pearson correlation coefficient is used to measure the similarity \citep{recom_86} \citep{recom_97}:
\begin{equation}\label{eq:12}
sim(x,y)= \frac {\sum_{s\in S_{xy}}(r_{x,s}-\bar{r_x})(r_{y,s}- \bar{r_y})}{\sqrt{\sum_{s \in S_{xy}}(r_{x,s}-\bar{r_x})^2 \sum_{s\in S_{xy}}(r_{y,s}- \bar{r_y})^2}}
\end{equation}

\item \textbf{Cosine based similarity}
In the cosine-based approach [15, 91], the two users x and y are treated as two vectors in m-dimensional space, where $m=|S_{xy} |$. Then, the similarity between two vectors can be measured by computing the cosine of the angle between them:
\begin{equation}\label{eq:13}
sim(x,y)= cos(\vec{x}  ,\vec {y}) = \frac{\vec{x} . \vec {y}} {\|\vec{x}\|_2 \times \|\vec{y}\|_2 } = 
\frac{\sum _{i=1}^{k}r_{x,a}r_{y,a} }{\sqrt {\sum_{a\in S_{xy}}r^{2}_{x,a}}{\sqrt {\sum_{a\in A_{xy}}r^{2}_{y,a}}}}
\end{equation}
where $\vec{x} . \vec {y}$  denotes the dot-product between the vectors $\vec{x} \,and \,\vec {y}$ .
\end{itemize}


\subsection{Limitation}
\begin{itemize}
\item {\textbf{New user problem:} It is the same problem as with content-based systems. In order to make accurate recommendations, the system must first learn the user’s preferences from the ratings that the user makes.}

\item{\textbf{New article problem}
New articles are added regularly to recommender systems. Collaborative systems rely solely on users’ preferences to make recommendations. Therefore, until the new article is rated by a substantial number of users, the recommender system would not be able to recommend it.}

\item{\textbf{Sparsity}
In any recommender system, the number of ratings already obtained is usually very small compared to the number of ratings that need to be predicted. Effective prediction of ratings from a small number of examples is important. Also, the success of the collaborative recommender system depends on the availability of a critical mass of users. For example, there may be many articles that have been rated only by few people and these articles would be recommended very rarely, even if those few users gave high ratings to them. Also, for the user whose tastes are unusual compared to the rest of the population there will not be any other users who are particularly similar, leading to poor recommendations \citep{recom_8}.}
\end{itemize}

\section{Collaboration via content}\label{coll_content}
Collaborative methods look for similarities between users to make predictions. Typically, the pattern of ratings of individual users is used to determine similarity. Such a correlation is most meaningful when there are many objects rated in common between users.
The content-based profile of each user is exploited to detect similarities among users. Recall that the user’s content-based profile contains weights for the concepts that indicate that a user will like an article. When computing Pearson’s r between two profiles, any word in one profile but not another is treated as having a weight of 0 in the other profile. As in collaborative filtering, the prediction made is determined by a weighted average of all user’s predictions for that item using the correlation between profiles as the weight.

\subsection{Building user Profile}
For the content-based approach which we are taking, there are four essential requirements:
\begin{table}[ht]
\caption{The four essential requirements} % title of Table
\centering  % used for centering table
\begin{tabular}{c c} % centered columns (5 columns)
\hline\hline                        %inserts double horizontal lines
Requirement & Description\\ [0.5ex] % inserts table 
%heading
\hline                  % inserts single horizontal line
w & A representation of an article. \\ % inserting body of the table
m & A representation of the user's interests.\\
r(w,m)& A function to determine the pertinence of an article given a user's interests.\\
u(w,m,s)& A function returning an updated user profile m given the user's feedback s on a page w. \\[1ex]      % [1ex] adds vertical space
\hline %inserts single line
\end{tabular}
\label{table:2} % is used to refer this table in the text
\end{table}

We used LSA for document similarity and hence each article $a$ is represented as vector $(w_1, w_2, ...,w_p)$ where $p$ is the numnber of concepts, as described in chapter ~\ref{sim}, this vector representation is used both for pages, and for the model of the user's interests,
the user profile m. In order to measure how well a page $w$ matches a profile $m$, we use a variant of the standard IR cosine measure as showed in equation ~\ref{eq:measue} \citep{recom_1003}. 
the profile of the user is built incrementally, as it is updated after the user gives a rate to an article $a$ as in equation ~\ref{eq:feedback} where $m$ is the user profile of the user, $a$ is the representation of the article and $s$ is the feeback of the user on the article (we translate the scale shown in following Figure to the integers 3, 2, 1, 0, -1,-2, -3).

\begin{equation}
r(w,m)= w.m
\label{eq:measue}
\end{equation}

Updating m also corresponds to a normal operation in retrospective IR: relevance feedback (Rocchio 1971).We use a simple update rule:


\begin{equation}
u(a,m,s) =m+sa
\label{eq:feedback}
\end{equation}

We assume that a user's interests change over time, and furthermore that this happens in real time, regardless of the number of recommendations requested per day. This process is modeled using a simple decay function-each night all the weights in the profiles are multiplied by 0.97.

\subsection{Recommending articles}
 When the user requires a recommendation, the system starts first by retrieving the unread documents $U$(the system keeps track of the documents that the user read before), let correlation between the user $x$ and her neighbour $y$ be $corr_{i,j}$ which is computed using Pearson correlation coefficient formula ~\ref{eq:corr}, after that the system checks the rate given by each neighbor $j$ to each unread document $U_i$ which is dentoed by $r_{j,U_i}$. 
 
 \begin{equation}\label{eq:corr}
sim(x,y)= cos(\vec{x}  ,\vec {y}) = \frac{\vec{x} . \vec {y}} {\|\vec{x}\|_2 \times \|\vec{y}\|_2 } = 
\frac{\sum _{i=1}^{k}r_{x,a}r_{y,a} }{\sqrt {\sum_{a\in A_{xy}}r^{2}_{x,a}}{\sqrt {\sum_{s\in A_{xy}}r^{2}_{y,a}}}}
\end{equation}

The system expect the user rate given by the user to each unread document $a$ using equation ~\ref{eq:reco_val}, hence the top $N$ documents can be obtained.

\begin{equation}\label{eq:reco_val}
r_{c,a}= k\sum_{ c'\in \hat{C}} sim(c,c')\times r_{c',a}
\end{equation}


where multiplier k serves as a normalizing factor and is usually selected as shown in formula ~\ref{k}
\begin{equation}\label{k}
k = \frac{1}{\sum_{c' \in \hat{C}} |sim(c,c')|}
\end{equation}

 
\section{User's Feedback}\label{feedback}
\subsection{Explicit feedback}
Explicit feedback is not a good choice for two reasons. Users will have to rate items frequently and will be very reluctant in doing so as their ratings expire quickly.

\subsection{Implicit feedback}
Acquiring feedback by observing the users’ actions is favorable. A user that selects and reads a document for a certain amount of time provides a strong indication that the document contains information a user is interested in. After such action the documents is therefore classified as a positive example. Finding negative examples is much more problematic. Users ignoring links to documents could be seen as a clue. This action does not provide strong evidence however as users might not have noticed the link or visit the document later. Another possible clue is a document that is being read for a very short time but this could be caused by the fact that the document is similar to what the user has already seen although the topic of the document is still interesting to the user. Classifying documents as negative based on weak assumptions leads to much noise in the training data and may result in inaccurate predictions. Negative examples will therefore not be used. In short, the user model has to be dynamic and learned from positive examples only.
\section{Using LSA in Recommendation}\label{adv_lsa}
Latent semantic analysis provides a vector of a predefined length (the number of documents used in building the term versus document matrix) for representing documents.
So, we proposed using LSA vector representation to represent both documents and users profile.
\subsection{Advantage of using LSA}
\begin{itemize}
\item  The length of both user profile vector and document is the same
\item  Calculating correlation between users is done in constant time
\item  Updating user profile is done in constant time just by adding the vector of the document multiplied by user feedback to the user vector
\end{itemize}








%----------------------------------------------------------------------------------------

